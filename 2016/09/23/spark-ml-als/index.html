<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>ALS矩阵分解算法 | 破而后立</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/3.0.3/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/2.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">ALS矩阵分解算法</h1><a id="logo" href="/.">破而后立</a><p class="description">凡事破必有一立</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/history/"><i class="fa fa-book"> 历史</i></a><a href="/guestbook/"><i class="fa fa-comments"> 留言</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">ALS矩阵分解算法</h1><div class="post-meta">Sep 23, 2016<span> | </span><span class="category"><a href="/categories/spasrk/">spasrk</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a data-disqus-identifier="2016/09/23/spark-ml-als/" href="/2016/09/23/spark-ml-als/#disqus_thread" class="disqus-comment-count"></a><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#阿基米德项目ALS矩阵分解算法应用案例"><span class="toc-number">1.</span> <span class="toc-text">阿基米德项目ALS矩阵分解算法应用案例</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#算法描述"><span class="toc-number">1.1.</span> <span class="toc-text">算法描述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#原理"><span class="toc-number">1.1.1.</span> <span class="toc-text">原理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#问题描述"><span class="toc-number">1.1.1.1.</span> <span class="toc-text">问题描述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#目标函数"><span class="toc-number">1.1.1.2.</span> <span class="toc-text">目标函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#模型求解"><span class="toc-number">1.1.1.3.</span> <span class="toc-text">模型求解</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ALS-WR模型"><span class="toc-number">1.1.1.4.</span> <span class="toc-text">ALS-WR模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#与其他矩阵分解算法的比较"><span class="toc-number">1.1.1.5.</span> <span class="toc-text">与其他矩阵分解算法的比较</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#伪代码"><span class="toc-number">1.1.2.</span> <span class="toc-text">伪代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#并行化方法"><span class="toc-number">1.1.3.</span> <span class="toc-text">并行化方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#文献"><span class="toc-number">1.1.4.</span> <span class="toc-text">文献</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#具体实现及调用"><span class="toc-number">1.2.</span> <span class="toc-text">具体实现及调用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#模型调用"><span class="toc-number">1.2.1.</span> <span class="toc-text">模型调用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#案例描述"><span class="toc-number">1.3.</span> <span class="toc-text">案例描述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#业务问题描述及分析"><span class="toc-number">1.3.1.</span> <span class="toc-text">业务问题描述及分析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#问题描述-1"><span class="toc-number">1.3.1.1.</span> <span class="toc-text">问题描述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#简要分析"><span class="toc-number">1.3.1.2.</span> <span class="toc-text">简要分析</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据的准备"><span class="toc-number">1.3.2.</span> <span class="toc-text">数据的准备</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#算法的运行及模型生成"><span class="toc-number">1.3.3.</span> <span class="toc-text">算法的运行及模型生成</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#性能"><span class="toc-number">1.3.3.1.</span> <span class="toc-text">性能</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#模型"><span class="toc-number">1.3.3.2.</span> <span class="toc-text">模型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#模型的评估"><span class="toc-number">1.3.4.</span> <span class="toc-text">模型的评估</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#与mahout的对比"><span class="toc-number">1.4.</span> <span class="toc-text">与mahout的对比</span></a></li></ol></li></ol></div></div><div class="post-content"><h1 id="阿基米德项目ALS矩阵分解算法应用案例"><a href="#阿基米德项目ALS矩阵分解算法应用案例" class="headerlink" title="阿基米德项目ALS矩阵分解算法应用案例"></a>阿基米德项目ALS矩阵分解算法应用案例</h1><p>原文地址：<br><a href="https://github.com/ceys/jdml/wiki/ALS" target="_blank" rel="external">阿基米德项目ALS矩阵分解算法应用案例</a><br><a href="http://www.cnblogs.com/lengyue365/p/5689219.html" target="_blank" rel="external">格式比较好的</a></p>
<h2 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h2><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><h4 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h4><p>ALS的矩阵分解算法常应用于推荐系统中，将用户(user)对商品(item)的评分矩阵，分解为用户对商品隐含特征的偏好矩阵，和商品在隐含特征上的映射矩阵。与传统的矩阵分解SVD方法来分解矩阵R($R\in \mathbb{R}^{m\times n}$)不同的是，ALS(alternating least squares)希望找到两个低维矩阵，以 $\tilde{R} = XY$ 来逼近矩阵R，其中 ，$X\in \mathbb{R}^{m\times d}$，$Y\in \mathbb{R}^{d\times n}$，d 表示降维后的维度，一般 d&lt;&lt;r，r表示矩阵 R 的秩，$r&lt;&lt;min(m,n)$。</p>
<h4 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h4><ul>
<li><p>为了找到低维矩阵X,Y最大程度地逼近矩分矩阵R，最小化下面的平方误差损失函数。<br><code>$$L(X,Y) = \sum_{u,i}(r_{ui} - x_{u}^{T}y_{i})^{2}......(1)$$</code></p>
</li>
<li><p>为防止过拟合给公式 (1) 加上正则项，公式改下为： <code>$$L(X,Y) = \sum_{u,i}(r_{ui} - x_{u}^{T}y_{i})^{2} + \lambda (\left | x_{u}\right |^{2} +　\left | y_{i}\right |^{2})......(2)$$</code><br>其中$x<em>{u}\in \mathbb{R}^{d}，y</em>{i}\in \mathbb{R}^{d}$，$1\leqslant u\leqslant m$，$1\leqslant i\leqslant n$，$\lambda$是正则项的系数。</p>
</li>
</ul>
<h4 id="模型求解"><a href="#模型求解" class="headerlink" title="模型求解"></a>模型求解</h4><ul>
<li>固定Y，对$x<em>{u}$ 求导 $\frac{\partial L(X,Y)}{\partial x</em>{u}} = 0$，得到求解$x<em>{u}$的公式<br>`$$x</em>{u} = (Y^{T}Y + \lambda I )^{-1}Y^{T}r(u)……(3)$$`</li>
<li>同理固定X,可得到求解$y<em>{i}$的公式<br>`$$y</em>{i} = (X^{T}X + \lambda I )^{-1}X^{T}r(i)……(4)$$`<br>其中，$r<em>{u}\in \mathbb{R}^{n}$,$r</em>{i}\in \mathbb{R}^{m}$,I表示一个d * d的单位矩阵。</li>
<li>基于公式(3)、(4)，首先随机初始化矩阵X，然后利用公式(3)更新Y，接着用公式(4)更新X，直到计算出的RMSE(均方根误差)值收敛或迭代次数足够多而结束迭代为止。<br>其中，$\tilde{R} = XY$，$RMSE = \sqrt{\frac{\sum (R - \tilde{R})^{2}}{N}}$</li>
</ul>
<h4 id="ALS-WR模型"><a href="#ALS-WR模型" class="headerlink" title="ALS-WR模型"></a>ALS-WR模型</h4><p>以上模型适用于用户对商品的有明确的评分矩阵的场景，然而很多情况下用户没有明确的反馈对商品的偏好，而是通过一些行为隐式的反馈。比如对商品的购买次数、对电视节目收看的次数或者时长，这时我们可以推测次数越多，看得时间越长，用户的偏好程度越高，但是对于没有购买或者收看的节目，可能是由于用户不知道有该商品，或者没有途径获取该商品，我们不能确定的推测用户不喜欢该商品。ALS-WR通过置信度的权重来解决此问题，对于我们更确信用户偏好的项赋予较大的权重，对于没有反馈的项，赋予较小的权重。模型如下</p>
<ul>
<li>ALS-WR目标函数<br>`$\underset{x<em>{u},y</em>{i}}{min} L(X,Y) = \sum<em>{u,i}c</em>{ui}(p<em>{ui} - x</em>{u}^{T}y<em>{i})^{2} + \lambda (\left | x</em>{u}\right |^{2} +　\left | y<em>{i}\right |^{2})……(5)$<br>其中 $$p</em>{ui} = \begin{cases} &amp; \text{1 if } r<em>{ui} &gt; 0 \ &amp; \text{0 if } r</em>{ui} = 0 \end{cases}$$<br>$c<em>{ui} = 1 + \alpha r</em>{ui}$，$\alpha$是置信度系数</li>
<li>通过最小二乘法求解<br>$$x<em>{u} = (Y^{T}C^{u}Y + \lambda I )^{-1}Y^{T}C^{u}r(u)……(6)$$<br>$$y</em>{i} = (X^{T}C^{i}X + \lambda I )^{-1}X^{T}C^{i}r(i)……(7)$$<br>其中$C^{u}$是一$n\times n$维的个对角矩阵，$C<em>{ii}^{u} = c</em>{ui}$; 其中$C^{u}$是一$m\times m$维的个对角矩阵，$C<em>{ii}^{u} = c</em>{ui}$</li>
</ul>
<h4 id="与其他矩阵分解算法的比较"><a href="#与其他矩阵分解算法的比较" class="headerlink" title="与其他矩阵分解算法的比较"></a>与其他矩阵分解算法的比较</h4><ul>
<li>在实际应用中，由于待分解的矩阵常常是非常稀疏的，与SVD相比，ALS能有效的解决过拟合问题。</li>
<li>基于ALS的矩阵分解的协同过滤算法的可扩展性也优于SVD。</li>
<li>与随机梯度下降的求解方式相比，一般情况下随机梯度下降比ALS速度快；但有两种情况ALS更优于随机梯度下降：1)当系统能够并行化时，ALS的扩展性优于随机梯度下降法。2）ALS-WR能够有效的处理用户对商品的隐式反馈的数据。</li>
</ul>
<h3 id="伪代码"><a href="#伪代码" class="headerlink" title="伪代码"></a>伪代码</h3><figure class="highlight cos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">import numpy</span><br><span class="line"></span><br><span class="line">def mf_als(<span class="keyword">R</span>, P, <span class="keyword">Q</span>, <span class="keyword">K</span>, steps=<span class="number">5000</span>, alpha=<span class="number">0.0002</span>, beta=<span class="number">0.02</span>):</span><br><span class="line">    <span class="keyword">Q</span> = <span class="keyword">Q</span>.T</span><br><span class="line">    <span class="keyword">for</span> step in xrange(steps): </span><br><span class="line">        <span class="keyword">for</span> i in xrange(len(P)):                              </span><br><span class="line">            e = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i in xrange(len(<span class="keyword">R</span>)):</span><br><span class="line">            <span class="keyword">for</span> <span class="keyword">j</span> in xrange(len(<span class="keyword">R</span>[i])):</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">R</span>[i][<span class="keyword">j</span>] &gt; <span class="number">0</span>:</span><br><span class="line">                    e = e + pow(<span class="keyword">R</span>[i][<span class="keyword">j</span>] - numpy.dot(P[i,:],<span class="keyword">Q</span>[:,<span class="keyword">j</span>]), <span class="number">2</span>)</span><br><span class="line">                    <span class="keyword">for</span> <span class="keyword">k</span> in xrange(<span class="keyword">K</span>):</span><br><span class="line">                        e = e + (beta/<span class="number">2</span>) * (pow(P[i][<span class="keyword">k</span>],<span class="number">2</span>) + pow(<span class="keyword">Q</span>[<span class="keyword">k</span>][<span class="keyword">j</span>],<span class="number">2</span>))</span><br><span class="line">        <span class="keyword">if</span> e &lt; <span class="number">0.001</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> P, <span class="keyword">Q</span>.T</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="keyword">R</span> = [</span><br><span class="line">     [<span class="number">5</span>,<span class="number">3</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">     [<span class="number">4</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">     [<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">5</span>],</span><br><span class="line">     [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">4</span>],</span><br><span class="line">     [<span class="number">0</span>,<span class="number">1</span>,<span class="number">5</span>,<span class="number">4</span>],</span><br><span class="line">    ]</span><br><span class="line">    <span class="keyword">R</span> = numpy.array(<span class="keyword">R</span>)</span><br><span class="line">    N, M, <span class="keyword">K</span> = len(<span class="keyword">R</span>), len(<span class="keyword">R</span>[<span class="number">0</span>]), <span class="number">2</span></span><br><span class="line">    P = numpy.random.rand(N,<span class="keyword">K</span>)</span><br><span class="line">    <span class="keyword">Q</span> = numpy.random.rand(M,<span class="keyword">K</span>)</span><br><span class="line"></span><br><span class="line">    nP, nQ = mf_als(<span class="keyword">R</span>, P, <span class="keyword">Q</span>, <span class="keyword">K</span>)</span><br><span class="line">    <span class="keyword">print</span> numpy.dot(nP, nQ.T)</span><br></pre></td></tr></table></figure>
<h3 id="并行化方法"><a href="#并行化方法" class="headerlink" title="并行化方法"></a>并行化方法</h3><p>整体思路就是把矩阵拆成行向量，分别来做最小二乘参数估计。</p>
<p>伪代码中，所有数据都被广播到了集群节点。实际代码中，只会向各节点分发其运算能用到的部分数据。</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"># <span class="keyword">M</span>： item个数， <span class="keyword">U</span>： user个数， F： 分解矩阵的秩</span><br><span class="line"># 初始化评分矩阵</span><br><span class="line">R = <span class="built_in">matrix</span>(rand(<span class="keyword">M</span>, F)) * <span class="built_in">matrix</span>(rand(<span class="keyword">U</span>, F).T)</span><br><span class="line">ms = <span class="built_in">matrix</span>(rand(<span class="keyword">M</span> ,F))</span><br><span class="line"><span class="keyword">us</span> = <span class="built_in">matrix</span>(rand(<span class="keyword">U</span>, F))</span><br><span class="line"></span><br><span class="line"># 将评分矩阵，item矩阵，user矩阵广播到所有节点</span><br><span class="line">Rb = <span class="keyword">sc</span>.broadcast(R)</span><br><span class="line">msb = <span class="keyword">sc</span>.broadcast(ms)</span><br><span class="line">usb = <span class="keyword">sc</span>.broadcast(<span class="keyword">us</span>)</span><br><span class="line"></span><br><span class="line"># 指定遍历次数ITERATIONS</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="keyword">range</span>(ITERATIONS):</span><br><span class="line">    # 固定user矩阵，分布式求解item矩阵</span><br><span class="line">    # 每个节点计算<span class="keyword">M</span>/slices个items</span><br><span class="line">    ms = <span class="keyword">sc</span>.parallelize(<span class="keyword">range</span>(<span class="keyword">M</span>), slices) \</span><br><span class="line">           .map(lambda x: <span class="keyword">update</span>(x, msb.value[x, :], usb.value, Rb.value)) \</span><br><span class="line">           .collect()</span><br><span class="line">    ms = <span class="built_in">matrix</span>(np.array(ms)[:, :, 0])      # collect() returns a <span class="keyword">list</span>, <span class="keyword">so</span> array ends up being</span><br><span class="line">                                            # a 3-<span class="keyword">d</span> array, we take the first 2 dims <span class="keyword">for</span> the <span class="built_in">matrix</span></span><br><span class="line">    # 广播更新后的item矩阵</span><br><span class="line">    msb = <span class="keyword">sc</span>.broadcast(ms)</span><br><span class="line"></span><br><span class="line">    # 固定item矩阵，分布式求解user矩阵</span><br><span class="line">    <span class="keyword">us</span> = <span class="keyword">sc</span>.parallelize(<span class="keyword">range</span>(<span class="keyword">U</span>), slices) \</span><br><span class="line">           .map(lambda x: <span class="keyword">update</span>(x, usb.value[x, :], msb.value, Rb.value.T)) \</span><br><span class="line">           .collect()</span><br><span class="line">    <span class="keyword">us</span> = <span class="built_in">matrix</span>(np.array(<span class="keyword">us</span>)[:, :, 0])</span><br><span class="line">    usb = <span class="keyword">sc</span>.broadcast(<span class="keyword">us</span>)</span><br><span class="line"></span><br><span class="line">    # 平方误差</span><br><span class="line">    <span class="keyword">error</span> = rmse(R, ms, <span class="keyword">us</span>)</span><br><span class="line"></span><br><span class="line"># 最小二乘更新数据</span><br><span class="line"># 输入：矩阵行index，要更新的特征向量，固定的特征矩阵，评分矩阵</span><br><span class="line">def <span class="keyword">update</span>(i, <span class="keyword">vec</span>, <span class="keyword">mat</span>, ratings):</span><br><span class="line">    uu = <span class="keyword">mat</span>.shape[0]</span><br><span class="line">    ff = <span class="keyword">mat</span>.shape[1]</span><br><span class="line"></span><br><span class="line">    # 变成可逆矩阵</span><br><span class="line">    XtX = <span class="keyword">mat</span>.T * <span class="keyword">mat</span></span><br><span class="line">    Xty = <span class="keyword">mat</span>.T * ratings[i, :].T</span><br><span class="line"></span><br><span class="line">    # 正则项</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="keyword">range</span>(ff):</span><br><span class="line">        XtX[j,j] += LAMBDA * uu</span><br><span class="line"></span><br><span class="line">    # XtXZ=XtY，求Z并返回</span><br><span class="line">    # 返回类型为二维数组。因为每次<span class="keyword">update</span>只计算一个向量，所以实际只有第一维有值。</span><br><span class="line">    <span class="keyword">return</span> np.linalg.solve(XtX, Xty)</span><br></pre></td></tr></table></figure>
<h3 id="文献"><a href="#文献" class="headerlink" title="文献"></a>文献</h3><ul>
<li><p><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.173.2797&amp;rep=rep1&amp;type=pdf" target="_blank" rel="external">Large-scale Parallel Collaborative Filtering for the Netfli Prize</a></p>
</li>
<li><p><a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=4781121" target="_blank" rel="external">Collaborative Filtering for Implicit Feedback Datasets</a></p>
</li>
<li><p><a href="http://rakaposhi.eas.asu.edu/cse494/lsi-for-collab-filtering.pdf" target="_blank" rel="external">MATRIX FACTORIZATION TECHNIQUES FOR RECOMMENDER SYSTEMS</a></p>
</li>
</ul>
<h2 id="具体实现及调用"><a href="#具体实现及调用" class="headerlink" title="具体实现及调用"></a>具体实现及调用</h2><h3 id="模型调用"><a href="#模型调用" class="headerlink" title="模型调用"></a>模型调用</h3><p><strong>输入数据结构与说明</strong>：</p>
<p><code>Rating(UserId:Int, ItemId:Int, Rating:toDouble)</code> 用户、商品id必须为整形，评分为浮点型。</p>
<p><strong>模型输出数据结构及说明</strong>：</p>
<p><code>RDD[(Id:Int, Array[feature:Double]]]</code> 可以分别输出userFeatures和itemFeatures。包含id和隐含特征值。</p>
<p><strong>推荐结果输出数据结构及说明</strong>：<br><code>Rating(UserId:Int, ItemId:Int, Rating:toDouble)</code> 用户、商品id与预测评分。</p>
<p><strong>算法调用语句示例</strong>：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.spark.mllib.recommendation.ALS</span><br><span class="line">import org.apache.spark.mllib.recommendation.Rating</span><br><span class="line"></span><br><span class="line">// <span class="keyword">Load</span> <span class="keyword">and</span> <span class="keyword">parse</span> the <span class="keyword">data</span></span><br><span class="line">val <span class="keyword">data</span> = sc.textFile(<span class="string">"mllib/data/als/test.data"</span>)</span><br><span class="line">val ratings = data.map(_.split(<span class="string">','</span>) <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="built_in">Array</span>(<span class="keyword">user</span>, item, rate) =&gt;  Rating(user.toInt, item.toInt, rate.toDouble)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">// <span class="keyword">Build</span> the recommendation <span class="keyword">model</span> <span class="keyword">using</span> ALS</span><br><span class="line">val numIterations = <span class="number">20</span></span><br><span class="line">val <span class="keyword">model</span> = ALS.train(ratings, <span class="number">1</span>, <span class="number">20</span>, <span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">// <span class="keyword">Evaluate</span> the <span class="keyword">model</span> <span class="keyword">on</span> rating <span class="keyword">data</span></span><br><span class="line">val usersProducts = ratings.map&#123; <span class="keyword">case</span> Rating(<span class="keyword">user</span>, product, rate)  =&gt; (<span class="keyword">user</span>, product)&#125;</span><br><span class="line">val predictions = model.predict(usersProducts).map&#123;</span><br><span class="line">    <span class="keyword">case</span> Rating(<span class="keyword">user</span>, product, rate) =&gt; ((<span class="keyword">user</span>, product), rate)</span><br><span class="line">&#125;</span><br><span class="line">val ratesAndPreds = ratings.map&#123;</span><br><span class="line">    <span class="keyword">case</span> Rating(<span class="keyword">user</span>, product, rate) =&gt; ((<span class="keyword">user</span>, product), rate)</span><br><span class="line">&#125;.join(predictions)</span><br><span class="line">val MSE = ratesAndPreds.map&#123;</span><br><span class="line">    <span class="keyword">case</span> ((<span class="keyword">user</span>, product), (r1, r2)) =&gt;  math.pow((r1- r2), <span class="number">2</span>)</span><br><span class="line">&#125;.reduce(_ + _)/ratesAndPreds.count</span><br><span class="line">println(<span class="string">"Mean Squared Error = "</span> + MSE)</span><br></pre></td></tr></table></figure>
<p><strong>性能参数配置</strong>：</p>
<figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">val conf = new SparkConf()</span><br><span class="line">  .<span class="keyword">set</span>(<span class="string">"spark.serializer"</span>, <span class="string">"org.apache.spark.serializer.KryoSerializer"</span>)</span><br><span class="line">  .<span class="keyword">set</span>(<span class="string">"spark.kryo.registrator"</span>,  classOf[ALSRegistrator].getName)</span><br><span class="line">    /*</span><br><span class="line">    Whether <span class="keyword">to</span> track references <span class="keyword">to</span> <span class="keyword">the</span> same object when serializing data <span class="keyword">with</span> Kryo, </span><br><span class="line">    which <span class="keyword">is</span> necessary <span class="keyword">if</span> your object graphs have loops </span><br><span class="line">    <span class="keyword">and</span> useful <span class="keyword">for</span> efficiency <span class="keyword">if</span> they <span class="keyword">contain</span> multiple copies <span class="keyword">of</span> <span class="keyword">the</span> same object. </span><br><span class="line">    Can be disabled <span class="keyword">to</span> improve performance <span class="keyword">if</span> you know this <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">the</span> case.</span><br><span class="line">    */</span><br><span class="line">  .<span class="keyword">set</span>(<span class="string">"spark.kryo.referenceTracking"</span>, <span class="string">"false"</span>)</span><br><span class="line">  .<span class="keyword">set</span>(<span class="string">"spark.kryoserializer.buffer.mb"</span>, <span class="string">"8"</span>)</span><br><span class="line">    /*</span><br><span class="line">    Number <span class="keyword">of</span> milliseconds <span class="keyword">to</span> wait <span class="keyword">to</span> <span class="built_in">launch</span> a data-<span class="keyword">local</span> task <span class="keyword">before</span> giving up <span class="keyword">and</span> launching <span class="keyword">it</span> <span class="keyword">on</span> a less-<span class="keyword">local</span> node. </span><br><span class="line">    You should increase this setting <span class="keyword">if</span> your tasks are long <span class="keyword">and</span> see poor locality, <span class="keyword">but</span> <span class="keyword">the</span> default usually works well.</span><br><span class="line">    */</span><br><span class="line">  .<span class="keyword">set</span>(<span class="string">"spark.locality.wait"</span>, <span class="string">"10000"</span>)</span><br></pre></td></tr></table></figure>
<p>val conf = new SparkConf()<br>  .set(“spark.serializer”, “org.apache.spark.serializer.KryoSerializer”)<br>  .set(“spark.kryo.registrator”,  classOf[ALSRegistrator].getName)<br>    /<em><br>    Whether to track references to the same object when serializing data with Kryo,<br>    which is necessary if your object graphs have loops<br>    and useful for efficiency if they contain multiple copies of the same object.<br>    Can be disabled to improve performance if you know this is not the case.
    </em>/<br>  .set(“spark.kryo.referenceTracking”, “false”)<br>  .set(“spark.kryoserializer.buffer.mb”, “8”)<br>    /<em><br>    Number of milliseconds to wait to launch a data-local task before giving up and launching it on a less-local node.<br>    You should increase this setting if your tasks are long and see poor locality, but the default usually works well.
    </em>/<br>  .set(“spark.locality.wait”, “10000”)</p>
<h2 id="案例描述"><a href="#案例描述" class="headerlink" title="案例描述"></a>案例描述</h2><h3 id="业务问题描述及分析"><a href="#业务问题描述及分析" class="headerlink" title="业务问题描述及分析"></a>业务问题描述及分析</h3><h4 id="问题描述-1"><a href="#问题描述-1" class="headerlink" title="问题描述"></a>问题描述</h4><p>在电子商务领域中，当用户面对大量的商品时，往往无法快速找到自己喜欢的商品，或者不是非常明确的知道自己喜欢商品。和搜索引擎相比的推荐系统通过研究用户的兴趣偏好，进行个性化计算，由系统发现用户的兴趣点，从而引导用户发现自己的需求。</p>
<h4 id="简要分析"><a href="#简要分析" class="headerlink" title="简要分析"></a>简要分析</h4><p>矩阵分解是推荐系统中非常重要的一种算法，它通过将用户对商品的评分矩阵（或者隐含数据），分解为用户对商品隐含特征的偏好矩阵，和商品在隐含特征上的映射矩阵。如果用户所偏好特征，在商品上基本都出现，我们可以认为这个商品是用户喜欢的，进而可以将该商品推荐给用户。</p>
<p>我们用历史的订单数据作为训练数据，来预测用户对未购买过的商品的偏好程度，将偏好程度最高topN的商品推荐给用户。</p>
<h3 id="数据的准备"><a href="#数据的准备" class="headerlink" title="数据的准备"></a>数据的准备</h3><p>图书品类下，2014年1月到5月的订单数据，取在1~4月和4~5月两个区间都有图书购物记录的用户。1~4月为训练数据，4~5月为测试数据。用户对商品有购买行为，则隐性反馈值为1。</p>
<h3 id="算法的运行及模型生成"><a href="#算法的运行及模型生成" class="headerlink" title="算法的运行及模型生成"></a>算法的运行及模型生成</h3><h4 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h4><ol>
<li><code>N = User*Item</code> N的最大值（理论估计+实际验证） 测试了两组数据集：</li>
</ol>
<p>第一组：</p>
<ul>
<li><p>训练： pair：6557620 用户：781030 商品：726490</p>
</li>
<li><p>测试： pair：3250426 用户：781030 商品：490257</p>
</li>
</ul>
<figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">N</span> = <span class="number">726490</span>*<span class="number">781030</span> = <span class="number">567410484700</span></span><br><span class="line"></span><br><span class="line">稀疏度 =pair/<span class="keyword">N</span> = <span class="number">0.0000115571</span></span><br></pre></td></tr></table></figure>
<ol>
<li><code>worker-num,worker-mem,blocks,kryo,kryo-reference,locality-wait</code> 等运行参数与数据量对一轮迭代时间的影响。</li>
<li>运行时rdd的transform和action的运算时间与shuffle大小。</li>
</ol>
<h4 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h4><p>数据性质：</p>
<pre><code>稀疏性（行为（评分、购买），品类）
</code></pre><p>参数选择：</p>
<pre><code>lambda，alpha，R，iter
</code></pre><h3 id="模型的评估"><a href="#模型的评估" class="headerlink" title="模型的评估"></a>模型的评估</h3><p><strong>矩阵分解的评估</strong></p>
<ul>
<li>原始矩阵为R，预测的为$\tilde{R} = U^{T}V$，用RMSE来评估预测的效果。<br>$$RMSE = \sqrt{\frac{\sum (R - \tilde{R})^{2}}{N}}$$<br>其中N为中所有求和的项数</li>
</ul>
<p><strong>推荐效果的评估</strong></p>
<ul>
<li><p>对推荐预测的效果一般用准确率(precision)和召回率(recall)来衡量。R(u)是根据用户在训练集上的行为给用户推荐的列表，T(u)是用户在测试集上的行为列表。则有</p>
<p>召回率<br>$$Recall = \frac{\sum<em>{u\in U }\left |R(u)\bigcap T(u) \right |}{\sum</em>{u\in U }\left |T(u) \right |}$$</p>
<p>准确率<br>$$Precise = \frac{\sum<em>{u\in U }\left |R(u)\bigcap T(u) \right |}{\sum</em>{u\in U }\left |R(u) \right |}$$</p>
</li>
</ul>
<h2 id="与mahout的对比"><a href="#与mahout的对比" class="headerlink" title="与mahout的对比"></a>与mahout的对比</h2><p>mahout与spark性能对比</p>
<ul>
<li>数据量 6991409行，134M</li>
<li>集群环境：mahout与spark安装在同一集群环境</li>
<li>影响运行时间的参数：降维后的秩 30，迭代次数 30，mahout与spark设置相同</li>
<li>运行时间：mahout(10个reduce) 运行180 minutes，spark 运行 40 minutes</li>
</ul>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://jackalope.cn/2016/09/23/spark-ml-als/" data-id="ciz86h6re002ak0eka6zmkmtj" class="article-share-link">分享到</a><div class="tags"><a href="/tags/als-spark-ml/">als spark ml</a></div><div class="post-nav"><a href="/2016/09/23/spark-tips/" class="pre">spark-tips</a><a href="/2016/09/23/js-dataTables-mergeCells/" class="next">dataTables合并单元格的实现方法</a></div><div id="disqus_thread"><script>var disqus_shortname = 'hedgehog-zowie';
var disqus_identifier = '2016/09/23/spark-ml-als/';
var disqus_title = 'ALS矩阵分解算法';
var disqus_url = 'http://jackalope.cn/2016/09/23/spark-ml-als/';
(function() {
  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//hedgehog-zowie.disqus.com/count.js" async></script></div></div></div></div><div class="pure-u-1-4"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://jackalope.cn"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Flume/">Flume</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/HBase/">HBase</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java基础/">Java基础</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java总结/">Java总结</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hadoop/">hadoop</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hbase/">hbase</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hive/">hive</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/java基础/">java基础</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/js/">js</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/mysql/">mysql</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/shell/">shell</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/spark/">spark</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/spasrk/">spasrk</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/spring/">spring</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/sqoop/">sqoop</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/jni/" style="font-size: 15px;">jni</a> <a href="/tags/hbase/" style="font-size: 15px;">hbase</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/hadoop/" style="font-size: 15px;">hadoop</a> <a href="/tags/HBase/" style="font-size: 15px;">HBase</a> <a href="/tags/hive/" style="font-size: 15px;">hive</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/io/" style="font-size: 15px;">io</a> <a href="/tags/nio/" style="font-size: 15px;">nio</a> <a href="/tags/集合/" style="font-size: 15px;">集合</a> <a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/Flume/" style="font-size: 15px;">Flume</a> <a href="/tags/多线程/" style="font-size: 15px;">多线程</a> <a href="/tags/als-spark-ml/" style="font-size: 15px;">als spark ml</a> <a href="/tags/spark/" style="font-size: 15px;">spark</a> <a href="/tags/shell/" style="font-size: 15px;">shell</a> <a href="/tags/mysql/" style="font-size: 15px;">mysql</a> <a href="/tags/sqoop/" style="font-size: 15px;">sqoop</a> <a href="/tags/spring-spring-data-hadoop/" style="font-size: 15px;">spring spring-data hadoop</a> <a href="/tags/js/" style="font-size: 15px;">js</a> <a href="/tags/js-dataTables/" style="font-size: 15px;">js dataTables</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2016/10/14/flume-trouble-shooting/">flume-trouble-shooting</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/14/spring-trouble-shooting/">sqoop-trouble-shooting</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/14/sqoop-trouble-shooting/">sqoop-trouble-shooting</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/14/shell-trouble-shooting/">shell-trouble-shooting</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/14/spark-trouble-shooting/">spark-trouble-shooting</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/27/hive-trouble-shooting/">hive-trouble-shooting</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/27/hbase-trouble-shooting/">hbase-trouble-shooting</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/23/hbase-tips/">hbase-tips</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/23/spark-tips/">spark-tips</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/23/spark-ml-als/">ALS矩阵分解算法</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-comment-o"> 最近评论</i></div><script type="text/javascript" src="//hedgehog-zowie.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://www.haomwei.com/" title="屠城" target="_blank">屠城</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">破而后立.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>